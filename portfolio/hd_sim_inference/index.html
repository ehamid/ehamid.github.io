<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body>
<p>Preprint on Arxiv: <a href="https://arxiv.org/abs/1909.03540">https://arxiv.org/abs/1909.03540</a></p>

<p>In this project we developed methods for constructing confidence intervals and hypothesis tests for the linear component of high-dimensional single-index models.
Single-index models generalize linear models by allowing the reponse $ y $ to depend on a non-linear function of a linear combination of the predictors:
\[ y = g(\langle x, \beta \rangle ) \]
This can avoid curse of dimensionality because we are not dealing with a fully non-parametric model $y = g(x)$ which suffers from curse of dimensionality. Even for a high-dimensional \(\beta\), we still estimate \(\beta\) if it is sparse and the design is elliptically symmetric.</p>

<p>The code for experiments in the paper is available on github: <a href="https://github.com/ehamid/sim_debiasing">https://github.com/ehamid/sim_debiasing</a></p>

<figure class="half ">
  
    
      <a href="/assets/images/hd_sim/link.png">
          <img src="/assets/images/hd_sim/link.png" alt="Using Hermite expansions to estimate link function">
      </a>
    
  
    
      <a href="/assets/images/hd_sim/histogram.png">
          <img src="/assets/images/hd_sim/histogram.png" alt="Histogram comparing efficient and plain de-biased estimates">
      </a>
    
  
  
    <figcaption>More efficient estimation using Hermite polynomials
</figcaption>
  
</figure>

</body></html>
